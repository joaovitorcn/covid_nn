{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "teste NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw3YhV3_IIDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d4b11ba6-c8af-4cf7-ae10-fbff4a2a4f89"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections\n",
        "import numpy as np\n",
        "import re\n",
        "from functions import logistic_reg,xg_boost,process_data_rs,run_xgboost,resultado,run_logreg\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5hnG-xYJd7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4ab5ce31-0541-406d-ff7f-ab0f1cd1430a"
      },
      "source": [
        "dates = ['DATA_SINTOMAS','DATA_CONFIRMACAO','DATA_EVOLUCAO','DATA_EVOLUCAO_ESTIMADA']\n",
        "df = pd.read_csv('20200702.csv',sep=';',encoding='iso-8859-1',parse_dates=dates)\n",
        "\n",
        "len(df.columns)\n",
        "\n",
        "print('Casos Totais: {}'.format(df['HOSPITALIZACAO'].value_counts().sum()))\n",
        "print('Casos Em Acompanhamento: {}'.format(df.loc[df['EVOLUCAO'] == 'EM ACOMPANHAMENTO']['EVOLUCAO'].value_counts().sum()))\n",
        "print('Casos Hospitalizados:{}'.format(df['HOSPITALIZACAO'].value_counts().values[1]))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Casos Totais: 28171\n",
            "Casos Em Acompanhamento: 4240\n",
            "Casos Hospitalizados:3454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_y8fOeYJgzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "process_data = process_data_rs(df)\n",
        "process_data = process_data.loc[process_data['EVOLUCAO'] != 'EM ACOMPANHAMENTO']\n",
        "process_data = process_data.drop(columns=['EVOLUCAO'])\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9egmDUGJhOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = model = pickle.load(open(\"cols.pkl\", 'rb'))\n",
        "cols = list(process_data.columns.values)\n",
        "\n",
        "for x in data:\n",
        "    if not x in cols:\n",
        "        process_data[x] = 0\n",
        "        \n",
        "for x in cols:\n",
        "    if not x in data:\n",
        "        process_data = process_data.drop(columns=[x])\n",
        "        \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW7CBamzKF5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92e35262-8f4e-40fc-e461-b0efe01230e9"
      },
      "source": [
        "len(process_data.columns)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDv9jTCXLmET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  y = 'HOSPITALIZACAO'\n",
        "  X = process_data.drop(columns=y).to_numpy()\n",
        "  Y = process_data[y].to_numpy()\n",
        "  \n",
        "  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FoHOQkOVNF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "846Rc4tQJuAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75c4e186-b2a3-49ec-e342-99ae746f15f8"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "model_dense = Sequential()\n",
        "model_dense.add(Dense(64, input_dim=478, activation='relu'))\n",
        "model_dense.add(Dense(32, activation='relu'))\n",
        "model_dense.add(Dense(16, activation='relu'))\n",
        "model_dense.add(Dense(4, activation='relu'))\n",
        "model_dense.add(Dense(1, activation='sigmoid'))\n",
        "model_dense.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4U9qHwiKn72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26f78b4f-5d1a-47ec-f232-35a1be5aeab4"
      },
      "source": [
        "history = model_dense.fit(x_train, y_train, epochs=100, batch_size=64)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20341/20341 [==============================] - 1s 73us/step - loss: 0.5796 - accuracy: 0.8879\n",
            "Epoch 2/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.1450 - accuracy: 0.9603\n",
            "Epoch 3/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.1357 - accuracy: 0.9624\n",
            "Epoch 4/100\n",
            "20341/20341 [==============================] - 1s 55us/step - loss: 0.1280 - accuracy: 0.9645\n",
            "Epoch 5/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.1216 - accuracy: 0.9648\n",
            "Epoch 6/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.1170 - accuracy: 0.9654\n",
            "Epoch 7/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.1120 - accuracy: 0.9662\n",
            "Epoch 8/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.1082 - accuracy: 0.9665\n",
            "Epoch 9/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.1045 - accuracy: 0.9674\n",
            "Epoch 10/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.1016 - accuracy: 0.9677\n",
            "Epoch 11/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0980 - accuracy: 0.9683\n",
            "Epoch 12/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0960 - accuracy: 0.9682\n",
            "Epoch 13/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0925 - accuracy: 0.9697\n",
            "Epoch 14/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0902 - accuracy: 0.9695\n",
            "Epoch 15/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0879 - accuracy: 0.9706\n",
            "Epoch 16/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0861 - accuracy: 0.9710\n",
            "Epoch 17/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0833 - accuracy: 0.9717\n",
            "Epoch 18/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0833 - accuracy: 0.9716\n",
            "Epoch 19/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0808 - accuracy: 0.9725\n",
            "Epoch 20/100\n",
            "20341/20341 [==============================] - 1s 55us/step - loss: 0.0788 - accuracy: 0.9732\n",
            "Epoch 21/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0775 - accuracy: 0.9731\n",
            "Epoch 22/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0763 - accuracy: 0.9734\n",
            "Epoch 23/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0765 - accuracy: 0.9731\n",
            "Epoch 24/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0746 - accuracy: 0.9744\n",
            "Epoch 25/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0737 - accuracy: 0.9747\n",
            "Epoch 26/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0719 - accuracy: 0.9744\n",
            "Epoch 27/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0720 - accuracy: 0.9749\n",
            "Epoch 28/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0704 - accuracy: 0.9748\n",
            "Epoch 29/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0702 - accuracy: 0.9762\n",
            "Epoch 30/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0693 - accuracy: 0.9753\n",
            "Epoch 31/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0680 - accuracy: 0.9764\n",
            "Epoch 32/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0672 - accuracy: 0.9762\n",
            "Epoch 33/100\n",
            "20341/20341 [==============================] - 1s 55us/step - loss: 0.0666 - accuracy: 0.9768\n",
            "Epoch 34/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0656 - accuracy: 0.9773\n",
            "Epoch 35/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0667 - accuracy: 0.9761\n",
            "Epoch 36/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0639 - accuracy: 0.9770\n",
            "Epoch 37/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0631 - accuracy: 0.9782\n",
            "Epoch 38/100\n",
            "20341/20341 [==============================] - 1s 57us/step - loss: 0.0631 - accuracy: 0.9777\n",
            "Epoch 39/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0623 - accuracy: 0.9778\n",
            "Epoch 40/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0618 - accuracy: 0.9782\n",
            "Epoch 41/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0612 - accuracy: 0.9780\n",
            "Epoch 42/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0597 - accuracy: 0.9786\n",
            "Epoch 43/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0597 - accuracy: 0.9785\n",
            "Epoch 44/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0596 - accuracy: 0.9785\n",
            "Epoch 45/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0587 - accuracy: 0.9795\n",
            "Epoch 46/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0580 - accuracy: 0.9790\n",
            "Epoch 47/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0581 - accuracy: 0.9787\n",
            "Epoch 48/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0564 - accuracy: 0.9795\n",
            "Epoch 49/100\n",
            "20341/20341 [==============================] - 1s 55us/step - loss: 0.0573 - accuracy: 0.9794\n",
            "Epoch 50/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0552 - accuracy: 0.9800\n",
            "Epoch 51/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0544 - accuracy: 0.9808\n",
            "Epoch 52/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0542 - accuracy: 0.9801\n",
            "Epoch 53/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0540 - accuracy: 0.9803\n",
            "Epoch 54/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0524 - accuracy: 0.9813\n",
            "Epoch 55/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0540 - accuracy: 0.9803\n",
            "Epoch 56/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0531 - accuracy: 0.9810\n",
            "Epoch 57/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0514 - accuracy: 0.9811\n",
            "Epoch 58/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0508 - accuracy: 0.9815\n",
            "Epoch 59/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0505 - accuracy: 0.9811\n",
            "Epoch 60/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0489 - accuracy: 0.9822\n",
            "Epoch 61/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0495 - accuracy: 0.9820\n",
            "Epoch 62/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0490 - accuracy: 0.9816\n",
            "Epoch 63/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0486 - accuracy: 0.9811\n",
            "Epoch 64/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0491 - accuracy: 0.9819\n",
            "Epoch 65/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0467 - accuracy: 0.9824\n",
            "Epoch 66/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0487 - accuracy: 0.9822\n",
            "Epoch 67/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0464 - accuracy: 0.9825\n",
            "Epoch 68/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0464 - accuracy: 0.9837\n",
            "Epoch 69/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0458 - accuracy: 0.9831\n",
            "Epoch 70/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0465 - accuracy: 0.9825\n",
            "Epoch 71/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0461 - accuracy: 0.9831\n",
            "Epoch 72/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0461 - accuracy: 0.9828\n",
            "Epoch 73/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0451 - accuracy: 0.9827\n",
            "Epoch 74/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0450 - accuracy: 0.9832\n",
            "Epoch 75/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0439 - accuracy: 0.9831\n",
            "Epoch 76/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0459 - accuracy: 0.9829\n",
            "Epoch 77/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0445 - accuracy: 0.9835\n",
            "Epoch 78/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0440 - accuracy: 0.9825\n",
            "Epoch 79/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0435 - accuracy: 0.9833\n",
            "Epoch 80/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0428 - accuracy: 0.9841\n",
            "Epoch 81/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0428 - accuracy: 0.9834\n",
            "Epoch 82/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0427 - accuracy: 0.9836\n",
            "Epoch 83/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0425 - accuracy: 0.9845\n",
            "Epoch 84/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0437 - accuracy: 0.9834\n",
            "Epoch 85/100\n",
            "20341/20341 [==============================] - 1s 54us/step - loss: 0.0428 - accuracy: 0.9838\n",
            "Epoch 86/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0427 - accuracy: 0.9840\n",
            "Epoch 87/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0426 - accuracy: 0.9840\n",
            "Epoch 88/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0415 - accuracy: 0.9844\n",
            "Epoch 89/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0418 - accuracy: 0.9844\n",
            "Epoch 90/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0413 - accuracy: 0.9839\n",
            "Epoch 91/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0416 - accuracy: 0.9844\n",
            "Epoch 92/100\n",
            "20341/20341 [==============================] - 1s 53us/step - loss: 0.0412 - accuracy: 0.9842\n",
            "Epoch 93/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0403 - accuracy: 0.9853\n",
            "Epoch 94/100\n",
            "20341/20341 [==============================] - 1s 57us/step - loss: 0.0399 - accuracy: 0.9853\n",
            "Epoch 95/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0408 - accuracy: 0.9846\n",
            "Epoch 96/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0414 - accuracy: 0.9844\n",
            "Epoch 97/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0401 - accuracy: 0.9848\n",
            "Epoch 98/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0403 - accuracy: 0.9846\n",
            "Epoch 99/100\n",
            "20341/20341 [==============================] - 1s 52us/step - loss: 0.0405 - accuracy: 0.9847\n",
            "Epoch 100/100\n",
            "20341/20341 [==============================] - 1s 51us/step - loss: 0.0396 - accuracy: 0.9853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R343FHamKB_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06e1b6b3-1609-4471-f247-5782ba8859e2"
      },
      "source": [
        "eval_model=model_dense.evaluate(x_train, y_train)\n",
        "eval_model\n",
        "model_dense.save('dense_ network')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20341/20341 [==============================] - 1s 41us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QGNXRsRL_6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred= model_dense.predict(x_test)\n",
        "y_pred =(y_pred>0.5).astype(int)[:,0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbH3SNz7NQBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4ce4905a-a97a-4cb3-f3fc-52e560ffd7d0"
      },
      "source": [
        "resultado(y_test,y_pred),"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de 0: 3187, %: 0.8877437325905293 \n",
            "Numero de 1: 403, %: 0.11225626740947076\n",
            "\n",
            "Accuracy: 96.32%\n",
            "Resultado\n",
            "Correto Negativo    3116\n",
            "Correto Positivo     342\n",
            "Falso Negativo        71\n",
            "Falso Positivo        61\n",
            "Name: predict, dtype: int64\n",
            "\n",
            "Taxa de Acerto Negativos:97.8% \n",
            "Taxa de Acerto Positivos: 84.9%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QReEEXpFtV1w",
        "colab_type": "text"
      },
      "source": [
        "# **Conv net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab2GrW3KXgLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(20341,478,1,1)\n",
        "x_test = x_test.reshape(3590,478,1,1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjsE-RmDX58Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "conv_net = Sequential()\n",
        "conv_net.add(Conv2D(32, kernel_size=(1, 1),\n",
        "                 activation='relu',\n",
        "                 input_shape=(478,1,1)))\n",
        "conv_net.add(Conv2D(64, (1, 1), activation='relu'))\n",
        "conv_net.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "conv_net.add(Dropout(0.25))\n",
        "conv_net.add(Flatten())\n",
        "conv_net.add(Dense(128, activation='relu'))\n",
        "conv_net.add(Dropout(0.5))\n",
        "conv_net.add(Dense(1, activation='sigmoid'))\n",
        "conv_net.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ABD5384Yo84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc468f0e-0388-47dd-90c3-e8ac5a7f8eb3"
      },
      "source": [
        "history = conv_net.fit(x_train, y_train, epochs=100, batch_size=64)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20341/20341 [==============================] - 3s 151us/step - loss: 0.5758 - accuracy: 0.9510\n",
            "Epoch 2/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.3753 - accuracy: 0.9635\n",
            "Epoch 3/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.1834 - accuracy: 0.9644\n",
            "Epoch 4/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.1225 - accuracy: 0.9665\n",
            "Epoch 5/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.1207 - accuracy: 0.9674\n",
            "Epoch 6/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.1024 - accuracy: 0.9661\n",
            "Epoch 7/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0897 - accuracy: 0.9668\n",
            "Epoch 8/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0874 - accuracy: 0.9661\n",
            "Epoch 9/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0852 - accuracy: 0.9670\n",
            "Epoch 10/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0838 - accuracy: 0.9679\n",
            "Epoch 11/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0823 - accuracy: 0.9686\n",
            "Epoch 12/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0791 - accuracy: 0.9697\n",
            "Epoch 13/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0784 - accuracy: 0.9704\n",
            "Epoch 14/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0787 - accuracy: 0.9705\n",
            "Epoch 15/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0765 - accuracy: 0.9705\n",
            "Epoch 16/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0758 - accuracy: 0.9716\n",
            "Epoch 17/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0750 - accuracy: 0.9722\n",
            "Epoch 18/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0742 - accuracy: 0.9718\n",
            "Epoch 19/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0736 - accuracy: 0.9706\n",
            "Epoch 20/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0692 - accuracy: 0.9727\n",
            "Epoch 21/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0721 - accuracy: 0.9718\n",
            "Epoch 22/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0697 - accuracy: 0.9724\n",
            "Epoch 23/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0691 - accuracy: 0.9732\n",
            "Epoch 24/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0687 - accuracy: 0.9732\n",
            "Epoch 25/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0689 - accuracy: 0.9745\n",
            "Epoch 26/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0663 - accuracy: 0.9733\n",
            "Epoch 27/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0666 - accuracy: 0.9732\n",
            "Epoch 28/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0677 - accuracy: 0.9736\n",
            "Epoch 29/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0631 - accuracy: 0.9743\n",
            "Epoch 30/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0649 - accuracy: 0.9743\n",
            "Epoch 31/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0655 - accuracy: 0.9747\n",
            "Epoch 32/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0646 - accuracy: 0.9748\n",
            "Epoch 33/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0633 - accuracy: 0.9744\n",
            "Epoch 34/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0623 - accuracy: 0.9756\n",
            "Epoch 35/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0637 - accuracy: 0.9749\n",
            "Epoch 36/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0650 - accuracy: 0.9738\n",
            "Epoch 37/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0623 - accuracy: 0.9750\n",
            "Epoch 38/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0615 - accuracy: 0.9744\n",
            "Epoch 39/100\n",
            "20341/20341 [==============================] - 2s 93us/step - loss: 0.0620 - accuracy: 0.9754\n",
            "Epoch 40/100\n",
            "20341/20341 [==============================] - 2s 93us/step - loss: 0.0612 - accuracy: 0.9755\n",
            "Epoch 41/100\n",
            "20341/20341 [==============================] - 2s 92us/step - loss: 0.0613 - accuracy: 0.9751\n",
            "Epoch 42/100\n",
            "20341/20341 [==============================] - 2s 92us/step - loss: 0.0588 - accuracy: 0.9770\n",
            "Epoch 43/100\n",
            "20341/20341 [==============================] - 2s 92us/step - loss: 0.0611 - accuracy: 0.9758\n",
            "Epoch 44/100\n",
            "20341/20341 [==============================] - 2s 89us/step - loss: 0.0592 - accuracy: 0.9754\n",
            "Epoch 45/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0577 - accuracy: 0.9779\n",
            "Epoch 46/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0605 - accuracy: 0.9763\n",
            "Epoch 47/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0602 - accuracy: 0.9771\n",
            "Epoch 48/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0595 - accuracy: 0.9758\n",
            "Epoch 49/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0574 - accuracy: 0.9767\n",
            "Epoch 50/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0587 - accuracy: 0.9767\n",
            "Epoch 51/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0589 - accuracy: 0.9754\n",
            "Epoch 52/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0566 - accuracy: 0.9770\n",
            "Epoch 53/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0585 - accuracy: 0.9766\n",
            "Epoch 54/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0597 - accuracy: 0.9764\n",
            "Epoch 55/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0583 - accuracy: 0.9774\n",
            "Epoch 56/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0594 - accuracy: 0.9765\n",
            "Epoch 57/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0567 - accuracy: 0.9769\n",
            "Epoch 58/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0582 - accuracy: 0.9769\n",
            "Epoch 59/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0558 - accuracy: 0.9779\n",
            "Epoch 60/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0566 - accuracy: 0.9770\n",
            "Epoch 61/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0550 - accuracy: 0.9787\n",
            "Epoch 62/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0559 - accuracy: 0.9778\n",
            "Epoch 63/100\n",
            "20341/20341 [==============================] - 2s 88us/step - loss: 0.0531 - accuracy: 0.9780\n",
            "Epoch 64/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0557 - accuracy: 0.9772\n",
            "Epoch 65/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0533 - accuracy: 0.9791\n",
            "Epoch 66/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0550 - accuracy: 0.9768\n",
            "Epoch 67/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0539 - accuracy: 0.9780\n",
            "Epoch 68/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0548 - accuracy: 0.9765\n",
            "Epoch 69/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0541 - accuracy: 0.9774\n",
            "Epoch 70/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0520 - accuracy: 0.9775\n",
            "Epoch 71/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0529 - accuracy: 0.9795\n",
            "Epoch 72/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0542 - accuracy: 0.9774\n",
            "Epoch 73/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0545 - accuracy: 0.9777\n",
            "Epoch 74/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0534 - accuracy: 0.9782\n",
            "Epoch 75/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0522 - accuracy: 0.9782\n",
            "Epoch 76/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0550 - accuracy: 0.9781\n",
            "Epoch 77/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0544 - accuracy: 0.9781\n",
            "Epoch 78/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0532 - accuracy: 0.9787\n",
            "Epoch 79/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0525 - accuracy: 0.9787\n",
            "Epoch 80/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0518 - accuracy: 0.9782\n",
            "Epoch 81/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0524 - accuracy: 0.9772\n",
            "Epoch 82/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0527 - accuracy: 0.9793\n",
            "Epoch 83/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0527 - accuracy: 0.9785\n",
            "Epoch 84/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0515 - accuracy: 0.9790\n",
            "Epoch 85/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0523 - accuracy: 0.9790\n",
            "Epoch 86/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0525 - accuracy: 0.9788\n",
            "Epoch 87/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0506 - accuracy: 0.9794\n",
            "Epoch 88/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0518 - accuracy: 0.9785\n",
            "Epoch 89/100\n",
            "20341/20341 [==============================] - 2s 88us/step - loss: 0.0529 - accuracy: 0.9789\n",
            "Epoch 90/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0515 - accuracy: 0.9783\n",
            "Epoch 91/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0497 - accuracy: 0.9788\n",
            "Epoch 92/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0503 - accuracy: 0.9796\n",
            "Epoch 93/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0513 - accuracy: 0.9778\n",
            "Epoch 94/100\n",
            "20341/20341 [==============================] - 2s 87us/step - loss: 0.0526 - accuracy: 0.9782\n",
            "Epoch 95/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0509 - accuracy: 0.9792\n",
            "Epoch 96/100\n",
            "20341/20341 [==============================] - 2s 86us/step - loss: 0.0509 - accuracy: 0.9790\n",
            "Epoch 97/100\n",
            "20341/20341 [==============================] - 2s 88us/step - loss: 0.0508 - accuracy: 0.9789\n",
            "Epoch 98/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0514 - accuracy: 0.9785\n",
            "Epoch 99/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0516 - accuracy: 0.9787\n",
            "Epoch 100/100\n",
            "20341/20341 [==============================] - 2s 85us/step - loss: 0.0507 - accuracy: 0.9785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcxlcRrdX5_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ab567a2-435e-492e-f82c-61b85208282b"
      },
      "source": [
        "eval_model=conv_net.evaluate(x_train, y_train)\n",
        "eval_model\n",
        "conv_net.save('conv_net')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20341/20341 [==============================] - 1s 54us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0K-UAATtc9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred= conv_net.predict(x_test)\n",
        "y_pred =(y_pred>0.5).astype(int)[:,0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoMqTRfNtema",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1aae1447-8102-4a14-945c-a42f75f9ebdc"
      },
      "source": [
        "resultado(y_test,y_pred),"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de 0: 3199, %: 0.8910863509749304 \n",
            "Numero de 1: 391, %: 0.10891364902506964\n",
            "\n",
            "Accuracy: 96.82%\n",
            "Resultado\n",
            "Correto Negativo    3131\n",
            "Correto Positivo     345\n",
            "Falso Negativo        68\n",
            "Falso Positivo        46\n",
            "Name: predict, dtype: int64\n",
            "\n",
            "Taxa de Acerto Negativos:97.9% \n",
            "Taxa de Acerto Positivos: 88.2%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}